---
title: "James SSN Predictions"
author: "Michael McManus, Travis Linscome-Hatfield"
date: "12/03/2024"
output:
  html_document:
    fig_caption: yes
    number_sections: false
    toc: yes
    toc_float:  yes
    code_folding: hide
    self_contained: yes
    theme: lumen
editor_options: 
  chunk_output_type: console
---


# Outline
Start with a clean environment. This script like all the scripts runs as a stand-alone so that means there is some redundancy in having to modify and transform covariates.

The purpose of this script is to make sure both obs and preds have the same covariates. This is required so that the SSN model built from the obs can then applied to make predictions at the preds. The 48 preds where withheld from from the SSN model building to provide an independent data set for measuring the predictive performance of the SSN model. The 48 preds were collected from spatially balanced probabilistic surveys done from 2019-2022.

Three modifications were made to the SSN WS-WQ model, ssn_wswq_reml1, from script 05 in attempts to get a better predictive model. Those modifications included:
1) Added a partition factor statement to the model based on parallel coordinate plot in script 05 and a boxplot of evelvation made in this script (see NMC Elevation Boxplots by Subbasins
2) Based on the literature, tested 3 additional covariates to try and get a better fitting and predictive model,
3) Tested the hypothesis that monitoring sites having upstream waterbodies furthest away would have higher VSCI.

With those modification evaluated, then the final model, which included the partition factor and the nearest distance to upstream waterbody covariate, was evaluated by comparing observed vsci to predicted vsci, first, for the 199 observations from 2001-2018 using leave-one-out-cross-validation (loocv). The second evaluation used the 48 predictions sites from 2019-2022 with their observed vsci compared to the predicted vsci from the SSN model. Both of those evaluations were done graphs of the observed values on the y-axis and predicted values on the x-axis.

Log Keeping log below for now when reach final version will delete.

01/24/2025 coded for status and trend station types so to evaluate ST_rand model

12/23/2024 Travis walked me through merging his interval_pred_upd branch with main repository on GitHub. Once that was done I pulled that from main repository to my local repository.


12/16/2024 trying to run distance hypothesis using binomial, numerically coded waterbody upstream, 0 is absent and 1 is present, and distance upstream to nearest waterbody as continuous covariate. 

11/25/2024 using James_071024_pluspreds as ssn object as has all 48 prediction points in one shapefile. And bringing additional covariates. Needing to assign 0's to preds_2019_2022 that initially had dist_nearest_up_wb_km set to NA for 31 of 48 prediction points.

11/19/2024 trying to run TLH code chunk for prediction interval graph

On 10/24/2024, went through the code with Travis and now runs without errors all chunks above Status vs Trend Predictions chunk. Pushed to repository.

Trying again on 08/14/2024 to push this code up to github repository.
On 08/13/2024, pushed to github. Trying push again as I don't see this code
on github. 

On 07/12/2024 need to make sure that james_071024.ssn, with PRISM data, gives same prediction output as previous ssn object. It does.

On 07/02/2024 R version 4.4.1 was installed.
On 07/01/2024 added code to include partition factor assignment to preds.

On 06/28/2024 added code to run a parition factor model.

On 06/17/2024 running code to get predictions for 2019-2020 that I put into a geopackage so I map and plot se vs prediction in QGIS.

On 05/14/2024 running code as updated R, RTools, and RStudio on 05/08/2024.

On 04/19/2024 also specify spatial autocovariance of tail down exponential and Euclidean exponential. Also, run MLR of mixed geography using impervious cover of all 4 geographies (to identify high collinearity), elevation at watershed, DO, tothab, and l_tn, and Lower James subbasin. Does that combination of variables better fit and outperform watershed-only model?

On 04/18/2024 now using vsci as response variable not y2.

On 04/17/2024 now using James041724.ssn as it has climate PRISM data out of StreamCat of precip_mm, Tmean, and Tmax.

On 04/09/2024 Mike Dumelle recommended:  1) use untransformed vsci, 2) include absence/presence binary land cover with percent land cover, and 3) include year.

On 04/04/2024 now using James040424.ssn as Ellen D'Amico from Pegasus updated Preds_2021_2022 points.

On 03/27/2024, Using code from step1_james_eda_v1.Rmd, but now specifying preds1 to bring in 22 points from 2019-2020 VDEQ monitoring and preds2 to bring in 26 points from 2021-2022 VDEQ monitoring using current SSN from James.ssn_032224.zip.
# Libraries
```{r setup,message=FALSE, warning=FALSE, collapse=TRUE}

library(SSN2)
library(tidyverse)
library(janitor)
library(readxl)
library(sf)
library(dummy)
library(mapview)
library(leafpop) # for popups in mapview
library(leafsync) # sync mapview maps
library(webshot2) # png of mapview maps
library(GGally)  # parallel coordinate plot
library(performance) # mlr diagnostics
library(car) # added variable plots visualize slopes
library(plotly)
library(corrr) # tidyverse correlation package
library(tmap) # for publication quality maps note this is version tmap_3.3-4 and version 4 is now out
library(tmaptools)
library(shiny)
library(shinyjs) # for tmap color palette

sessionInfo()

# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base     
# 
# other attached packages:
#  [1] corrr_0.4.4        plotly_4.10.4      performance_0.12.2
#  [4] GGally_2.2.1       leafpop_0.1.0      mapview_2.11.2    
#  [7] dummy_0.1.3        sf_1.0-16          readxl_1.4.3      
# [10] janitor_2.2.0      lubridate_1.9.3    forcats_1.0.0     
# [13] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       
# [16] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      
# [19] ggplot2_3.5.1      tidyverse_2.0.0    SSN2_0.2.1 


knitr::opts_chunk$set(message=FALSE, warning=FALSE,collapse = T)
```

# 1.0 Load SSN Observations and Preds
Notice this import explicitly brings in the prediction points. The SSN object alwyas contained obs and preds, but until now we never called out the preds. Both the obs and preds to have the same covariates.
```{r ssn_obs_preds}
# now bringing predpts 2019-2022 combined
# current ssn
j_ssn1a <- SSN2::ssn_import("ssn_object/James_071024_pluspreds.ssn", predpts = c("Preds_2019_2022"),
overwrite = FALSE)

names(j_ssn1a)
summary(j_ssn1a)

DFobs <- SSN2::ssn_get_data(j_ssn1a) %>% clean_names(.)

preds1 <- SSN2::ssn_get_data(j_ssn1a, name = "Preds_2019_2022") %>% clean_names(.)


```


# 2.0 Steps for working with preds based on obs

Note that both obs and preds need to be in the SSN object that is modeled. This results in the SSN model object having all the variables needed for the SSN predict function.
	1. Make factors of vahusb and year.
	2. Log total nitrogen. 
	3. Include additional covariates of wastewater treatment plant, depth to bedrock, upstream waterbody as categorical absent or present, and continuous covariate of distance to nearest upstream waterbody.
	4. Empirical logit transformations for impervious and forest
	5. Dummy code transformation of factors for vahusb.

On 03/04/2029, realized I needed to add in imputing of 2 observed sites for total habitat scores. I need tot_hab for catchment and catchment-riparian in the mixed geographies SSN analysis. Saw this when I made scatter plot of covariates.

# 2.1 Total Habitat (RBP) score
Bring Total Habitat Score (TotHab) in from Wadeable_ProbMon_2001-2018_Final_Final.xslx spreadsheet so it can be joined to DFobs and then j_ssn1a. These 2 stations:  2-JKS070.97 and 2-DDY000.75_2017 do not have tothab as Emma confirmed in her 11/24/2023 email. Both sites are in Central Appalachian Ridges and Valleys. Both have high VSCI scores of 73.8 and 84.5 (the latter is max VSCI), respectively. I will impute their tothab scores. For trend station 2-DDY000.75_2017, I will average the scores of 172.5, 173.5, and 178 from 2011, 2013, and 2015, respectively. For  2-JKS070.97 on 3rd order, I averaged nearby sites 2-JKS076.16, has tothab of 162.0 on 3rd order, is upstream of 2-JKS070.97, about 16 km apart. Also used Back Creek site, 2-BCC001.90 (has tothab of 189.0 on 2nd order),  that flows parallel to Jackson River, where the 2 sites are, and Back Creek site is near confluence to Jackson River.  2-BCC001.90 is about 9 stream km from 2-JKS070.97. Added new variable tothab.

```{r tothab}

tothab_ds1 <- read_xlsx("data/Wadeable_ProbMon_2001-2018_Final_Final.xlsx", range = "Wadeable_ProbMon_2001-2018!D1:BK814")
                        
tothab_ds2 <- tothab_ds1 |>
  filter(SubBasin == "James") |>
  dplyr::select(StationID_Trend, TotHab) |>
  mutate_at(c('TotHab'), as.numeric)

summary(tothab_ds2$TotHab)

# 2-DDY000.75_2017 is on Daddy Run headwater of Calfpasture River
# https://stackoverflow.com/questions/32829358/dplyr-filter-with-sql-like-wildcard
dr_na <- filter(tothab_ds2, grepl("2-DDY000.75", StationID_Trend, fixed = TRUE))
summary(dr_na$TotHab)

tothab_ds3 <- tothab_ds2|>
  mutate(
    TotHab = case_when(StationID_Trend == "2-DDY000.75_2017" ~ 176.4,
       TRUE ~ TotHab))


# 2-JKS070.97 is on Jackson River
jr_na <- filter(tothab_ds3, StationID_Trend == "2-JKS076.16"| StationID_Trend == "2-BCC001.90")

summary(jr_na$TotHab)

tothab_ds4 <- tothab_ds3|>
  mutate(
    TotHab = case_when(StationID_Trend == "2-JKS070.97" ~ 175.5,
       TRUE ~ TotHab))
# no longer any NAs
summary(tothab_ds4$TotHab)

tothab_ds4 <- rename(tothab_ds4,c(tothab = TotHab, st_id_tren = StationID_Trend ))
head(tothab_ds4)

# add tothab as new variable
DFobs <- full_join(DFobs, tothab_ds4, by = join_by(station_id_2==st_id_tren))

names(DFobs)

# remove datasets not needed downstream
rm(tothab_ds1, tothab_ds2, dr_na, tothab_ds3, jr_na, tothab_ds4)
```

# 2.2 Transform Obs Covariates
On 01/24/2025 added code for st_type, status or trend station type.

On 12/16/2024 added binomial wbc, wbc_bin, coded as numeric 0 or 1 similar to Dumelle et al. 2023 coding in National Lake assessment conductivity paper.
 
On 11/25/2024 added WWTP, STATSGo_Set2, and waterbody covariates.
0n 06/28/20204 added for ju - yes and ju - no to test if partitioning on ju helpful first by looking at separate torgegrams and then in modeling.
On 04/10/2024 added code for a binary presence covariate for impervious cover at watershed extent.
```{r transform_obs}
# use code to evaluate vsci by year for trend sites if a random effect for trend stations is needed
DFobs <- DFobs %>%
  mutate(
    st_type = case_when(
      station_id_2 == "2-JKS028.69_2004" ~ "status",
      station_id_2 != "2-JKS028.69_2004" & station_id_2 != station_id ~ "trend",
      station_id_2 != "2-JKS028.69_2004" & station_id_2 == station_id ~ "status",
    )
  )
summary(as.factor(DFobs$st_type))

ggplot(DFobs, aes(x = st_type, y = vscivcpmi)) + geom_boxplot() + labs(title = "Obs from 2001-2018 (n=199)")

select(DFobs, station_id_2, st_type, vscivcpmi) %>% arrange(st_type, vscivcpmi, station_id_2) %>% print(n =Inf)

DFobs$year_f <- as.factor(DFobs$year)
DFobs$vahusb <- factor(DFobs$vahusb, levels = c("JU", "JM", "JR", "JA", "JL"))
summary(DFobs$vahusb)

DFobs <- DFobs %>%
  mutate(
    jl = case_when(
    vahusb != "JL" ~ 0,
    vahusb == "JL" ~1
  )
)

DFobs <- DFobs %>% 
  mutate(
    ju = case_when(
      vahusb == "JU" ~ "yes",
      .default = "no"
    )
  )
DFobs$ju <- factor(DFobs$ju, levels = c("yes","no"))
summary(DFobs$ju)

glimpse(DFobs)
# In ArcGIS these 2 fields are not numeric so have to mutate
DFobs2 <- DFobs %>% mutate_at(c('pct_for_c', 'pct_for_w'), as.numeric)

DFobs2$l_tn <- log(DFobs2$tn)

DFobs2$vsci <- round(DFobs2$vscivcpmi,1)

# WWTP data
wwtp_ds1 <- read.csv("data/WWTP_VA.csv") %>% clean_names(.)

DFobs2 <- left_join(DFobs2, wwtp_ds1, by = join_by(feature_id == comid))

DFobs2 <- DFobs2 %>% 
  mutate(
    wwtp = case_when(
      wwtp_all_dens_ws > 0 ~ "yes",
      wwtp_all_dens_ws == 0 ~ "no"
    )
  )

DFobs2$wwtp <- factor(DFobs2$wwtp, levels = c("yes","no"))
summary(DFobs2$wwtp)

# Statgo2 Set 2 variables, use RckDepWs
statsgo_set2 <- read.csv("data/STATSGO_Set2_VA.csv") %>% clean_names(.)

names(statsgo_set2)

DFobs2 <- left_join(DFobs2, statsgo_set2, by = join_by(feature_id == comid))

# Waterbody data
wb_ds1 <- read.csv("data/ObservationPoints_DistancesUpstream_100424.csv") %>% clean_names(.)
class(wb_ds1)
names(wb_ds1)
head(wb_ds1)
str(wb_ds1)
summary(wb_ds1$num_waterbody_up, na.rm = TRUE)
summary(wb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)
wb_ds1$dist_nearest_up_wb_km <- round(wb_ds1$dist_nearest_up_wb_km, 1)

summary(wb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)
# file below provides a link to waterbody, and subsequently to DFobs data.
StationIDs_UniqLocIDs <- read.csv("data/StationIDs_UniqLocIDs.csv") %>% clean_names(.)

names(StationIDs_UniqLocIDs)

wb_ds2 <- left_join(StationIDs_UniqLocIDs, wb_ds1, by=join_by(uniq_loc_id))
names(wb_ds2)

# from help by = join_by(name == artist)
# station_id_2 and station_id are both long station trend names
DFobs2 <- left_join(DFobs2, wb_ds2, by = join_by(station_id_2==station_id))
names(DFobs2)
DFobs2 <- DFobs2 %>% 
  mutate(
    wbc = case_when(
      incl_nhdwb == "yes" ~ "present",
      incl_nhdwb != "yes" ~ "absent"
    )
  )

class(DFobs2$wbc)

DFobs2$wbc <- factor(DFobs2$wbc, levels = c("present", "absent"))
summary(DFobs2$wbc)

# adding binomial wbc, wbc_bin, coded as numeric 0 or 1 similar to Dumelle et al. 2023 coding in National Lake assessment conductivity paper.

DFobs2 <- DFobs2 %>% 
  mutate(
    wbc_bin = case_when(
      incl_nhdwb == "yes" ~ 1,
      incl_nhdwb != "yes" ~ 0
    )
  )

class(DFobs2$wbc_bin)
DFbos2 <- as.numeric(DFobs2$wbc_bin)
class(DFobs2$bin_wbc)

summary(DFobs2$dist_nearest_up_wb_km)

DFobs2$dist_nearest_up_wb_km[is.na(DFobs2$dist_nearest_up_wb_km)] <- 0

summary(DFobs2$dist_nearest_up_wb_km)

names(DFobs2)

class(DFobs2)
# note ssn_put_data requires sf object and SSN2 object
j_ssn2 <-  SSN2::ssn_put_data(DFobs2,j_ssn1a)
# just doing this assignment so not have to rename objects
j_ssn3 <- j_ssn2

# VARIABLE ADJUSTMENT ZONE 4
### Variables to apply empirical logit transformation
emplog_vars <- c("pct_for_w","pct_imp_w","pct_crop_w","pct_hay_w","pct_grs_w","pct_shrb_w","pct_for_wr","pct_imp_rp_w","pct_crop_wr","pct_hay_wr","pct_grs_wr","pct_shrb_wr","pct_for_c","pct_imp_c","pct_crop_c","pct_hay_c","pct_grs_c", "pct_shrb_c", "pct_for_cr","pct_imp_rp_c","pct_crop_cr","pct_hay_cr","pct_grs_cr","pct_shrb_cr")

# remove geometry so empirical logit can be applied
DFobsz <- st_set_geometry(DFobs2, NULL)
################################################################
################################################################


## transform these variables and put the new values into new columns in DFobs
for(var in emplog_vars){
  ### create new tranformed data column to preserve the original
  new_nm <- paste0(var,"_emplog")
  dat_vec_obs <- DFobsz[,var]
  # dat_vec_preds <- DFpreds[,var]
  
  #converting to 0-1 range
  dat_vec_obs <- dat_vec_obs/100
  # dat_vec_preds <- dat_vec_preds/100
  
  # dat_vec[dat_vec == 1] <- .9999
  # dat_vec[dat_vec == 0] <- .0001
  
  if(any(dat_vec_obs > 1 | dat_vec_obs < 0)){
    cat("ERROR: percentage variables outside logical bounds")
  }
  
  small_dat_vec_obs <- dat_vec_obs[dat_vec_obs <1 & dat_vec_obs >0]
  # small_dat_vec_preds <- dat_vec_preds[dat_vec_preds <1 & dat_vec_preds >0]
  op1_obs <- small_dat_vec_obs
  op2_obs<- 1-small_dat_vec_obs
  # op1_preds <- small_dat_vec_preds
  # op2_preds <- 1-small_dat_vec_preds
  
  ## minimum of op1 op2
  delt_obs <- min(c(op1_obs,op2_obs))
  # delt_preds <- min(c(op1_preds,op2_preds))
  
  ## getting set of frequencies
  freqs_obs <- NULL
  for(i in 1:length(dat_vec_obs)){
    if(dat_vec_obs[i] <= delt_obs){
      freqs_obs[i] <- delt_obs/2
    }else if(dat_vec_obs[i] >= 1- delt_obs){
      freqs_obs[i] <- 1-(delt_obs/2)
    }else{
      freqs_obs[i] <-dat_vec_obs[i]
    }
  }
  
 # freqs_preds <- NULL
 # for(i in 1:length(dat_vec_preds)){
 #   if(dat_vec_preds[i] <= delt_preds){
 #     freqs_preds[i] <- delt_preds/2
 #   }else if(dat_vec_preds[i] >= 1- delt_preds){
 #     freqs_preds[i] <- 1-(delt_preds/2)
 #   }else{
 #     freqs_preds[i] <-dat_vec_preds[i]
  #  }
 # }
  
  ##getting logits
  logits_obs <- log(freqs_obs/(1-freqs_obs))
  DFobsz[,new_nm] <- logits_obs
  
  # logits_preds <- log(freqs_preds/(1-freqs_preds))
  # DFpreds[,new_nm] <- logits_preds
}

DFobsz <- DFobsz %>%
  mutate(
    imp_w_pres = case_when(
    pct_imp_w_emplog <= -8.111428 ~ 0,
    pct_imp_w_emplog > -8.111428 ~1
  )
)

head(DFobsz$imp_w_pres)
head(DFobsz$pct_imp_w)

names(DFobsz)
DFobsz2 <- dplyr::select(DFobsz, c(station_id_2, pct_for_w_emplog:imp_w_pres))
# put transformed covariates in an SF object
DFobs2a <- full_join(DFobs2, DFobsz2, by = join_by(station_id_2))

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(DFobs2a,j_ssn3)

# dummy code 5 vahusb with base being JU, James Upper
vahusb <- dplyr::select(DFobsz, vahusb)
summary(vahusb)
glimpse(vahusb)

vahusb_d <- (data.frame(dummy(vahusb)))
# 5 levels need only n-1 =4 dummy variables, removed base level of JU by dropping first column
vahusb_d <- vahusb_d[c(-1)]
dim(vahusb_d)
head(DFobsz$vahusb)
distinct(vahusb_d)
head(vahusb_d)
str(vahusb_d)
class(vahusb_d)

DFobsz <- cbind(DFobsz,vahusb_d)
names(DFobsz)

X1 <- DFobsz|>
   dplyr::select(station_id_2, vahusb_JM, vahusb_JR, vahusb_JA, vahusb_JL) %>%
  mutate_at(c('vahusb_JM', 'vahusb_JR', 'vahusb_JA', 'vahusb_JL'), as.numeric)
# X1 can only contain numeric or factor

str(X1)

# put dummy covariates in an SF object
DFobs3a <- full_join(DFobs2a, X1, by = join_by(station_id_2))
names(DFobs3a)

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(DFobs3a,j_ssn3)
```

# 2.2 Transform Pred Covariates
On 01/24/2025 added code for st_type, status or trend station type.

On 12/16/2024 added binomial wbc, wbc_bin, coded as numeric 0 or 1 similar to Dumelle et al. 2023 coding in National Lake assessment conductivity paper.

On 11/25/2024 have to assign 0's for 31 of 48 preds that had distances of NA and additional covariates.

Create station type, noting that 34 preds are status stations. Have 7 trends stations with 2 measurements for a total of 14 observatons. Compare summaries of obs to preds to see if distributions overlap or if a pred value might be outside of the range of obs. The latter situation might identify a potential extrapolation or outlier.
```{r transform_preds_stationtype}
# did this assignment so would not have to change all the object names below
preds3 <- preds1

# create same name as in obs models
preds3$tothab <- preds3$tot_hab
summary(preds3$tothab)
summary(DFobs3a$tothab)

preds3 <- preds3 %>%
  mutate(
    st_type = case_when(
    station_id ==  station_id_2 ~ "status",
    station_id != station_id_2 ~ "trend"
  )
)

summary(as.factor(preds3$st_type))

preds3$vsci <- round(preds3$vscivcpmi,1)
summary(preds3$vsci)

ggplot(preds3, aes(x = st_type, y = vsci)) + geom_boxplot() + labs(title = "Preds 2019-2022 (n=48)")

select(preds3, station_id_2, st_type, vsci) %>% arrange(st_type, station_id_2, vsci) %>% print(n =Inf)

preds3 %>%
  group_by(st_type) %>%
  summarize(min = fivenum(vsci)[1],
            low = fivenum(vsci)[2],
            median = fivenum(vsci)[3],
            mean = mean(vsci, na.rm = TRUE),
            upper = fivenum(vsci)[4],
            max = fivenum(vsci)[5],
            count = dplyr::n()) %>%
  print(n = Inf)

DFobs3a %>%
  group_by(st_type) %>%
  summarize(min = fivenum(vsci)[1],
            low = fivenum(vsci)[2],
            median = fivenum(vsci)[3],
            mean = mean(vsci, na.rm = TRUE),
            upper = fivenum(vsci)[4],
            max = fivenum(vsci)[5],
            count = dplyr::n()) %>%
  print(n = Inf)
```

Creating subbasin factors and logging total nitrogen.
```{r }
preds3$year_f <- as.factor(preds3$year)
preds3$vahusb <- factor(preds3$vahusb, levels = c("JU", "JM", "JR", "JA", "JL"))
summary(preds3$vahusb)

preds3 <- preds3 %>%
  mutate(
    jl = case_when(
    vahusb != "JL" ~ 0,
    vahusb == "JL" ~1
  )
)

preds3 <- preds3 %>% 
  mutate(
    ju = case_when(
      vahusb == "JU" ~ "yes",
      .default = "no"
    )
  )
preds3$ju <- factor(preds3$ju, levels = c("yes","no"))
summary(preds3$ju)


preds3$l_tn <- log(preds3$tn)
summary(preds3$l_tn)
summary(DFobs3a$l_tn)

```

Wastewater treatment plants and statsgo2 covariates for preds
```{r wwtp_preds}
# WWTP data loaded from obs so comment  out
# wwtp_ds1 <- read.csv("E:/R_vdeq_nhdplus/WWTP_VA.csv") %>% clean_names(.)

preds3 <- left_join(preds3, wwtp_ds1, by = join_by(feature_id == comid))

preds3 <- preds3 %>% 
  mutate(
    wwtp = case_when(
      wwtp_all_dens_ws > 0 ~ "yes",
      wwtp_all_dens_ws == 0 ~ "no"
    )
  )

preds3$wwtp <- factor(preds3$wwtp, levels = c("yes","no"))
summary(preds3$wwtp)

# loaded from obs so commented out
# Statgo2 Set 2 variables, use RckDepWs
#statsgo_set2 <- read.csv("E:/R_vdeq_nhdplus/STATSGO_Set2_VA.csv") %>% clean_names(.)

names(statsgo_set2)

preds3 <- left_join(preds3, statsgo_set2, by = join_by(feature_id == comid))
```

Waterbody dat for preds.
```{r preds_waterbody}
# Preds Waterbody data
preds1wb_ds1 <- read.csv("data/PredictionPoints_2019_2020_DistancesUpstream_091924.csv") %>% clean_names(.)

preds2wb_ds1 <- read.csv("data/PredictionPoints_2021_2022_DistancesUpstream_091924.csv") %>% clean_names(.)

predsallwb_ds1 <- bind_rows(preds1wb_ds1, preds2wb_ds1)

class(predsallwb_ds1)
names(predsallwb_ds1)
head(predsallwb_ds1)
str(predsallwb_ds1)
summary(predsallwb_ds1$num_waterbody_up, na.rm = TRUE)
summary(predsallwb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)
predsallwb_ds1$dist_nearest_up_wb_km <- round(predsallwb_ds1$dist_nearest_up_wb_km, 1)

summary(predsallwb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)

summary(predsallwb_ds1$dist_nearest_up_wb_km)

predsallwb_ds1$dist_nearest_up_wb_km[is.na(predsallwb_ds1$dist_nearest_up_wb_km)] <- 0

summary(predsallwb_ds1$dist_nearest_up_wb_km)
summary(DFobs3a$dist_nearest_up_wb_km)

# station_id_2 and station_id are both long station trend names
preds3 <- left_join(preds3, predsallwb_ds1, by = join_by(station_id_2 == station_id))
names(preds3)

preds3 <- preds3 %>% 
  mutate(
    wbc = case_when(
      incl_nhdwb == "yes" ~ "present",
      incl_nhdwb != "yes" ~ "absent"
    )
  )

preds3$wbc <- factor(preds3$wbc, levels = c("present", "absent"))
summary(preds3$wbc)

preds3 <- preds3 %>% 
  mutate(
    wbc_bin = case_when(
      incl_nhdwb == "yes" ~ 1,
      incl_nhdwb != "yes" ~ 0
    )
  )

preds3$wbc_bin <- as.numeric(preds3$wbc_bin)

names(preds3)

class(preds3)
# note ssn_put_data requires sf object and SSN2 object
j_ssn3 <-  SSN2::ssn_put_data(preds3,j_ssn3, name = "Preds_2019_2022", resize_data = FALSE)
summary(j_ssn3)

# saveRDS(j_ssn3, file = "j_ssn3.rds")

```

Empirical logit transformation for preds.
```{r empirical_logit_preds}
# VARIABLE ADJUSTMENT ZONE 4
### Variables to apply empirical logit transformation
# emplog_vars <- c("pct_for_w","pct_imp_w","pct_crop_w","pct_hay_w","pct_grs_w","pct_shrb_w","pct_for_wr","pct_imp_rp_w","pct_crop_wr","pct_hay_wr","pct_grs_wr","pct_shrb_wr","pct_for_c","pct_imp_c","pct_crop_c","pct_hay_c","pct_grs_c", "pct_shrb_c", "pct_for_cr","pct_imp_rp_c","pct_crop_cr","pct_hay_cr","pct_grs_cr","pct_shrb_cr")

# remove geometry so empirical logit can be applied
predsz <- st_set_geometry(preds3, NULL)
################################################################
################################################################


## transform these variables and put the new values into new columns in preds
for(var in emplog_vars){
  ### create new tranformed data column to preserve the original
  new_nm <- paste0(var,"_emplog")
  dat_vec_obs <- predsz[,var]
  # dat_vec_preds <- DFpreds[,var]
  
  #converting to 0-1 range
  dat_vec_obs <- dat_vec_obs/100
  # dat_vec_preds <- dat_vec_preds/100
  
  # dat_vec[dat_vec == 1] <- .9999
  # dat_vec[dat_vec == 0] <- .0001
  
  if(any(dat_vec_obs > 1 | dat_vec_obs < 0)){
    cat("ERROR: percentage variables outside logical bounds")
  }
  
  small_dat_vec_obs <- dat_vec_obs[dat_vec_obs <1 & dat_vec_obs >0]
  # small_dat_vec_preds <- dat_vec_preds[dat_vec_preds <1 & dat_vec_preds >0]
  op1_obs <- small_dat_vec_obs
  op2_obs<- 1-small_dat_vec_obs
  # op1_preds <- small_dat_vec_preds
  # op2_preds <- 1-small_dat_vec_preds
  
  ## minimum of op1 op2
  delt_obs <- min(c(op1_obs,op2_obs))
  # delt_preds <- min(c(op1_preds,op2_preds))
  
  ## getting set of frequencies
  freqs_obs <- NULL
  for(i in 1:length(dat_vec_obs)){
    if(dat_vec_obs[i] <= delt_obs){
      freqs_obs[i] <- delt_obs/2
    }else if(dat_vec_obs[i] >= 1- delt_obs){
      freqs_obs[i] <- 1-(delt_obs/2)
    }else{
      freqs_obs[i] <-dat_vec_obs[i]
    }
  }
  
 # freqs_preds <- NULL
 # for(i in 1:length(dat_vec_preds)){
 #   if(dat_vec_preds[i] <= delt_preds){
 #     freqs_preds[i] <- delt_preds/2
 #   }else if(dat_vec_preds[i] >= 1- delt_preds){
 #     freqs_preds[i] <- 1-(delt_preds/2)
 #   }else{
 #     freqs_preds[i] <-dat_vec_preds[i]
  #  }
 # }
  
  ##getting logits
  logits_obs <- log(freqs_obs/(1-freqs_obs))
  predsz[,new_nm] <- logits_obs
  
  # logits_preds <- log(freqs_preds/(1-freqs_preds))
  # DFpreds[,new_nm] <- logits_preds
}

predsz <- predsz %>%
  mutate(
    imp_w_pres = case_when(
    pct_imp_w_emplog <= -8.111428 ~ 0,
    pct_imp_w_emplog > -8.111428 ~1
  )
)

head(predsz$imp_w_pres)
head(predsz$pct_imp_w)
names(predsz)
predsz2 <- dplyr::select(predsz, c(station_id_2, pct_for_w_emplog:imp_w_pres))
# put transformed covariates in an SF object
preds3a <- full_join(preds3, predsz2, by = join_by(station_id_2))
summary(preds3a$pct_imp_w_emplog)
class(preds3a)

# saveRDS(preds3a, file = "preds3a.rds")

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(preds3a,j_ssn3, name = "Preds_2019_2022", resize_data = FALSE)
summary(j_ssn3$preds$Preds_2019_2022$pct_imp_w_emplog)
summary(j_ssn3$obs$pct_imp_w_emplog)

summary(j_ssn3$preds$Preds_2019_2022$pct_imp_w)
summary(j_ssn3$obs$pct_imp_w)
```

Dummy code for preds
```{r dummycode_preds}
# dummy code 5 vahusb with base being JU, James Upper
vahusb <- dplyr::select(predsz, vahusb)
summary(vahusb)
glimpse(vahusb)

vahusb_d <- (data.frame(dummy(vahusb)))
# 5 levels need only n-1 =4 dummy variables, removed base level of JU by dropping first column
vahusb_d <- vahusb_d[c(-1)]
dim(vahusb_d)
head(predsz$vahusb)
distinct(vahusb_d)
head(vahusb_d)
str(vahusb_d)
class(vahusb_d)

predsz <- cbind(predsz,vahusb_d)
names(predsz)

P1 <- predsz|>
   dplyr::select(station_id_2, vahusb_JM, vahusb_JR, vahusb_JA, vahusb_JL) %>%
  mutate_at(c('vahusb_JM', 'vahusb_JR', 'vahusb_JA', 'vahusb_JL'), as.numeric)
str(P1)

# P1 can only contain numeric or factor for 22 preds

# put dummy covariates in an SF object
preds3b <- full_join(preds3a, P1, by = join_by(station_id_2))
names(preds3b)

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(preds3b,j_ssn3, "Preds_2019_2022", resize_data = FALSE)

summary(j_ssn3)

# Check that afv_area is in SSN object
str(j_ssn3$preds$Preds_2019_2022$afv_area)
```

# 3.0 Create Distance Matrix
When using a new SSN object, such as James_071024_pluspreds.ssn have to create distance matrices. Ran first set of code and now see a distance matrix folder in where the SSN object is stored at:
ssn_object/James_071024_pluspreds.ssn and see sub folders for obs and Preds_2019_2022 subfolder.
Already run so commented out.
```{r distance_matrix}

# Distance matrix for obs and first set of prediction points from 2019-2022
# SSN2::ssn_create_distmat(j_ssn3, predpts = "Preds_2019_2022", overwrite = TRUE)


```



# 4.0 Ws-Wq Model
This is the SSN Ws-Wq model that was evaluated in script 05. Here is it run again and augmented with diagnostic and fitted values. The parallel coordinate plot of the augmented data frame was grouped by the 5 vahusb. The clustering of the JU variables in that plot is what suggested using the partition factor. See also, the NMC Elevation Boxplots under Figures for Presentation. See the description of partition factor under section 4.1.3 Advanced Features in An Introduction to Spatial Stream Network Modeling in R using SSN2.

The ssn_wswq is the base model, and subsequent models derived from the base model will be preceded by prefix and underscore to identify the essential purpose or hypothesis of the new model.
On 04/19/2024 kept tail down exponential and changed Euclidean to exponential based on models_yintercept.csv table.
On 04/10/2023 evaluated model using vsci, untransformed, and added imp_w_pres, a binary presence indicator of impervious cover. This was approach was used by Dumelle et al. 2023 in their spatial modeling of NLA conductivity.
```{r wswq_ssn_obs_fitted}
ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area"
)
summary(ssn_wswq_reml1)
varcomp(ssn_wswq_reml1)
loocv(ssn_wswq_reml1)

#plot(ssn_wswq_reml1, which = c(1:6))

tidy(ssn_wswq_reml1)

```

## 4.1 Mapview Standardized Residuals
```{r mapview_wswq_ssn_residuals}
aug_ssn_wswq_reml1 <- augment(ssn_wswq_reml1, drop = FALSE)
class(aug_ssn_wswq_reml1)

summary(aug_ssn_wswq_reml1$.std.resid)

mapview(aug_ssn_wswq_reml1, zcol = ".std.resid", alpha.regions = .8, legend = TRUE, popup = popupTable(aug_ssn_wswq_reml1, zcol = c(".std.resid")))

```

## 4.2 Parallel Coordinate Plot of Covariates by Subbasin
```{r pcp_covariates_subbasin}
# names(aug_ssn_wswq_reml1)
pcpobs <- ggparcoord(data = aug_ssn_wswq_reml1, columns = c(123, 136, 38, 167), groupColumn = "vahusb", scale = "std", showPoint = TRUE, title = "Observed Sites", alphaLines = 0.8, boxplot = FALSE)
pcpobs

```

## 4.3 Torgegram of Ws-Wq SSN Model Residuals
```{r torg_wswq_resids}
resid_ssn1 <- as.data.frame(aug_ssn_wswq_reml1)|>
   dplyr::select(station_id_2, .fitted, .resid, .std.resid)

class(resid_ssn1)
# names(resid_ssn1)

# put selected covariates in an SF object
DFobs4 <- full_join(DFobs3a, resid_ssn1, by = join_by(station_id_2))

# put SF object into SSN
j_ssn4 <-  SSN2::ssn_put_data(DFobs4,j_ssn3)

res_tg1 <- SSN2::Torgegram(.std.resid ~ 1, j_ssn4, type = c("flowuncon", "euclid"))
plot(res_tg1, main = "Torgegram of Standardized Residuals from WS-WQ SSN")

# do View to check the np is reasonably larger, greater than 30
View(res_tg1$euclid)
View(res_tg1$flowuncon)
# Follow three steps below for saving output as RDS and a geopackage geodatabase

# ssn_wswq_fit_reml1 <- dplyr::select(aug_ssn_wswq_reml1, c(station_id, station_id_2, year, vahusb, do, tn, tothab, l_tn, vscivcpmi, pct_imp_c, pct_imp_w, elev_ws, pct_imp_w_emplog, vsci, .fitted, .std.resid))

# saveRDS(ssn_wswq_fit_reml1, file = "outputs/ssn_wswq_fit_reml1.rds")

# st_write(ssn_wswq_fit_reml1, dsn = file.path(getwd(), "ssn_wswq_fit_reml1.gpkg"), layer = "ssn_wswq_fit_reml1", driver = "GPKG", quiet = FALSE, append = FALSE)

```

# 5.0 Partitioned Ws-Wq Model
The p_ssn_wswq model below has the partitioned factor of ju, Upper James. The models z1-z3 tested different coding and how different fixed and random effects compared to ssn_wswq_reml1. Finally, z4 model had a better fit, based on AIcc, than ssn_wswq_reml1. Also, the RMSPE is slightly smaller for the z4 model, and its cor2 is slightly larger.

On 12/26/2024 commented out models z1-z3

On 11/25/2024 why does z4ssn_wswq_ml1 model give much more reasonable range estimates than reml model?
On 07/03/2024 need to look at diagnostic plots of partition model. Diagnostic plots are saved as Word files at E:\R_vdeq_sci\Working\Data\neptune_analysis\scripts_by_basin.
On 06/28/2024, I coded for a partition factor base on JU subbasin versus non-JU subasins , partly because parallel coordinate plot showed JU to differ in covariates and vsci from rest of subbasins. Results from dummy coded model above match factor coded model below. Also, on 06/20/2024 compared the Watershed ssn model to a model with a random effect of year. The Watershed ssn model had a much lower AICc than the model with a random effect of year.
```{r wswq_ssn_partition}

p_ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area",
  partition_factor = ~ ju
)
summary(p_ssn_wswq_reml1)
varcomp(p_ssn_wswq_reml1)
loocv(p_ssn_wswq_reml1) %>% print(n = Inf)

glances(ssn_wswq_reml1,p_ssn_wswq_reml1)

# plot(p_ssn_wswq_reml1, which = c(1:6))

tidy(p_ssn_wswq_reml1)
```
 
## 5.1 Mapview Standardized Residuals
```{r mapview aug_p_wswq_reml1}
aug_p_wswq_reml1 <- augment(p_ssn_wswq_reml1, drop = FALSE)
summary(aug_p_wswq_reml1$.std.resid)

mapview(aug_p_wswq_reml1, zcol = ".std.resid",  alpha.regions = .8, legend = TRUE, popup = popupTable(aug_p_wswq_reml1, zcol = c(".std.resid"))) 

```

## 5.2 Torgegram of p_WsWq SSN Residuals
```{r torg_wswq_resids}
p_resid_ssn1 <- as.data.frame(aug_p_wswq_reml1)|>
   dplyr::select(station_id_2, .fitted, .resid, .std.resid)

# put selected covariates in an SF object
DFobs5 <- full_join(DFobs3a, p_resid_ssn1, by = join_by(station_id_2))

# put SF object into SSN
j_ssn5 <-  SSN2::ssn_put_data(DFobs5,j_ssn3)

res_tg2 <- SSN2::Torgegram(.std.resid ~ 1, j_ssn5, type = c("flowuncon", "euclid"))
plot(res_tg2, main = "Torgegram of Standardized Residuals from Partitioned WS-WQ SSN")


```


## 5.3 p_WsWq SSN Model:  ML Estimation
Because we want to compare p_WsWq SSN model fit and predictions to models with different covariates, see additionaly hypotheses model in section 6.0, we need to  specify estimation method as ml.
```{r p_ssn_wswq_ml}
p_ssn_wswq_ml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ ju
)
summary(p_ssn_wswq_ml1)
varcomp(p_ssn_wswq_ml1)
loocv(p_ssn_wswq_ml1) %>% print(n = Inf)

```


# 6.0 Additional Hypotheses for Ws-Wq SSN model
The partitioned model, using ML estimation, beat out the additional hypotheses model based on AICc, RMSPE, and cor2. See Ver Hoef et al. 2014 for description of using ML estimation when comparing models with different covariates.

```{r additional_hypotheses}

a_ssn_wswq_ml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + rck_dep_ws + wwtp + wbc,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ju
)
summary(a_ssn_wswq_ml1)
varcomp(a_ssn_wswq_ml1)
loocv(a_ssn_wswq_ml1) %>% print(n = Inf)

glances(p_ssn_wswq_ml1,a_ssn_wswq_ml1)
loocv(a_ssn_wswq_ml1)

# plot(a_ssn_wswq_ml1, which = c(1:6))

# tidy(a_ssn_wswq_ml1)
```

## 6.1 Mapview Standardized Residuals
```{r mapview_a_ssn_wswq_reml1}
# inserted r in file name to indicate residuals now included
a_rssn_wswq_ml1 <- augment(a_ssn_wswq_ml1, drop = FALSE)
# note on 10/04/2024 fixed mapview so popupTable using correct object, had been pointing to ssn_wswq_reml1
summary(a_rssn_wswq_ml1$.std.resid)

mapview(a_rssn_wswq_ml1, zcol = ".std.resid",  alpha.regions = .8, legend = TRUE, popup = popupTable(a_rssn_wswq_ml1, zcol = c(".std.resid"))) 


```

# 7.0 Distance Hypothesis for WsWq SSN Model
On 12/26/2024 used geom_ribbon to make prediction interval.

On 12/16/2024 testing distance hypothesis of upstream waterbodies by now using wbc_bin and 
dist_nearest_up_wb_km with those covariates entered into the model as 
wbc_bin
wbc_bin:dist_nearest_up_wb_km.
This follows coding as used in Dumelle et al. 2023 paper. Using that coding produced a poorer fitting more complicated model than z4. Using just the continuous covariate of distance, as done on 11/19/2024, produces a better fitting model a5ssn_wswq_ml1. Model a5ssn_wswq_ml1 has slightly better values for RMSPE and cor2 than z4ssn_wswq_ml1. What does added variable plot of that model look like?


Run ML estimation when comparing to models with different covariates. Run with REML when comparing to models with different spatial autocovariances and for prediction.
On 11/19/2024 Tried running interaction of wbc*dist_nearest_up_wb_km, but got error of singular matrix. Consequently, only tested model using continuous covariate dist_nearest_up_wb_km.
Again, commented out plot(a5ssn_wswq_ml1, which = c(1:6)) as seems to prevent code running straight through. The a5ssn_wswq_ml1 model with only continuous covariate dist_nearest_up_wb_km has smaller AICc than z4 model.

## 7.1 ESDA on Distance Hypothesis
Running torgegram on SSN0 nugget mlr model as shown in section 4.1.1 of SSN2 vignette. Not seeing much in Torgegram plot.
```{r esda_distance_hypothesis}

ggplot(DFobs3a, aes(x = dist_nearest_up_wb_km, y = vsci)) + geom_point() + facet_wrap(vars(wbc))  + geom_smooth(method = "lm", se =TRUE)

ggplot(DFobs3a, aes(x = dist_nearest_up_wb_km, y = vsci)) + geom_point() + geom_smooth(method = "lm", se =TRUE)

d_tg <- Torgegram(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  type = c("flowcon", "flowuncon", "euclid")
)
plot(d_tg)
plot(d_tg, separate = TRUE)
View(d_tg$euclid)
View(d_tg$flowuncon)  
View(d_tg$flowcon) # low np
```

## 7.2 Check Nonspatial Diagnostics on Distance MLR Model
Get checks on collinearity, added variable plots and other diagnostics. Typical MLR diagnostics look good. 
```{r a5_mlr_diagnostics}
d_mlr1 <- lm(vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  data = DFobs3a)

summary(d_mlr1)
check_model(d_mlr1)
avPlots(d_mlr1)
```

## 7.3 d_ssn_wswq_ml1
```{r d_ssn_wswq_ml1}
d_ssn_wswq_ml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ju
)

summary(d_ssn_wswq_ml1)
varcomp(d_ssn_wswq_ml1)
loocv(d_ssn_wswq_ml1)
tidy(d_ssn_wswq_ml1)

# plot(d_ssn_wswq_reml1, which = c(1:6))


```

## 7.4 d_ssn_wswq_rem1
The reml estimation method is the one we want to use for obtainging variance composition from the varcomp function and for making predictions.
```{r d_ssn_wswq_ml1}
d_ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area",
  partition_factor = ~ju
)

summary(d_ssn_wswq_reml1)
varcomp(d_ssn_wswq_reml1)
loocv(d_ssn_wswq_reml1)

tidy(d_ssn_wswq_reml1)

# plot(d_ssn_wswq_reml1, which = c(1:6))

```

## 7.5 Mapview Standardized Residuals
```{r mapview aug_d_wswq_reml1}
aug_d_wswq_reml1 <- augment(d_ssn_wswq_reml1, drop = FALSE)
summary(aug_d_wswq_reml1$.std.resid)

mapview(aug_d_wswq_reml1, zcol = ".std.resid",  alpha.regions = .8, legend = TRUE, popup = popupTable(aug_d_wswq_reml1, zcol = c(".std.resid"))) 

```


# 8.0 Status and Trend WsWq SSN model
Using a more complex model with a covariate of station type, status versus trend, and a randome effect for repeated observations at trend stations, does not produce a better fitting or predictive model compared to the distance SSN model.
On 01/24/2025 inserted this code chunk to run status/trend random effects model, ssn_wswq_rand1_st, and compare it to distance model, with both models estimated by ml given different covariates.
```{r st_vs_distance}
st_ssn_wswq_rand1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km + st_type,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ju,
  random = ~ (1 | station_id)
)

summary(st_ssn_wswq_rand1)
varcomp(st_ssn_wswq_rand1)
loocv(st_ssn_wswq_rand1)

plot(st_ssn_wswq_rand1, which = c(1:6))

glances(d_ssn_wswq_ml1, st_ssn_wswq_rand1)


```

# 9.0 NMC Distance Model w/ and w/o Partition Factor
This compares the distance SSN model from section 7, which has a partition factor, to a distance model with no partition factor. The better model is the distance SSN model with the partition factor. This result was used in the NMC 2025 presentation.
02/19/2025 Making this comparison to include results in NMC 2025 presentation
```{r distance_with_without_partition}
#np stands for no partition factor

np_ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area"
)


summary(np_ssn_wswq_reml1)
varcomp(np_ssn_wswq_reml1)
loocv(np_ssn_wswq_reml1)
tidy(np_ssn_wswq_reml1)

glances(d_ssn_wswq_reml1, np_ssn_wswq_reml1)
```


# 10 Predictands from Distance WsWQ SSN Model

02/14/2025 trying to make scatter plot showing prediction error for status and trend stations
On 01/23/2025 the abrupt change from saw tooth prediction interval to
steady prediction interval is driven by the shorter range of vsci obs and vsci predictions for trend stations compared to the status status stations.
On 01/21/2025 added station type, st_type, of status or trend station as noticed first 11 stations with smallest .se.fit were trend stations.

Note for predictions want estimation method to be reml.
Looking to see if distance to nearest upstream waterbody covariate pulls outliers closer to 1:1 line, which is the a5 model.
```{r distance_hypothesis_preds}

# augment returns an sf object
# note level set to 0.90
aug_d_predict1ws_vsci <- augment(d_ssn_wswq_reml1, newdata = "Preds_2019_2022", se_fit = TRUE, interval = c("prediction"), level = 0.90)
# class(aug_a5predict1ws_vsci)
# names(aug_a5predict1ws_vsci)
aug_d_predict1ws_vsci$vsci_pred <- round(aug_d_predict1ws_vsci$.fitted,1)
aug_d_predict1ws_vsci$vsci_lwr <- round(aug_d_predict1ws_vsci$.lower,1)
aug_d_predict1ws_vsci$vsci_upr <- round(aug_d_predict1ws_vsci$.upper,1)
head(aug_d_predict1ws_vsci$.se.fit)
# Pineiro 2008 put observed on y and predict on x
# label specific points
# https://stackoverflow.com/questions/15624656/label-points-in-geom-point

select(aug_d_predict1ws_vsci, station_id_2, st_type, vsci, vsci_pred, .se.fit) %>% arrange(.se.fit) %>% print(n =48)

ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, size = .se.fit, shape = st_type, color = st_type)) + geom_point() + labs(x = "Predicted VSCI", y = "True VSCI, 2019-2022", title = "SSN Prediction Sites", shape = "Station Type", color = "Station Type") + xlim(35,80) + ylim(35,80) + scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

cor(aug_d_predict1ws_vsci$vsci_pred,aug_d_predict1ws_vsci$vsci, method = "pearson")

as.data.frame(aug_d_predict1ws_vsci)|>
  dplyr::select(vsci_pred,vsci)|>
  correlate()


```

# 11 Interactive Mapping of Predictands
## 11.1 VAHUSB Polygons
```{r vahusb_poly}
vahusb_poly <- sf::st_read("data/vahusb.shp")
# names(vahusb_poly)
# mapview(vahusb_poly)
mapview(vahusb_poly, zcol="VAHUSB", burst = TRUE)

vahusb_poly <- vahusb_poly %>% 
  mutate(
    subbasin = case_when(
      VAHUSB == "James River, Upper (Mountain)" ~ "JU",
      VAHUSB == "James River, Middle (Piedmont)" ~ "JM",
      VAHUSB == "James River- Rivanna River" ~ "JR",
      VAHUSB == "James River- Appomattox River" ~ "JA",
      VAHUSB == "James River, Lower (Tidal)" ~ "JL"
    )
  )
names(vahusb_poly)
mapview(vahusb_poly, zcol="subbasin", burst = TRUE)

vahusb_poly$subbasin <- factor(vahusb_poly$subbasin, levels = c("JU", "JM", "JR", "JA", "JL"))

# once made a factor do not need to do burst
mapview(vahusb_poly, zcol="subbasin")

```

## 11.2 Synced Maps
Synced maps are good for a quick, interactive visualization, but the workflow of make synced maps, use Rstudio export to save html locally, then open html in browser, snip a screenshot and paste into Powerpoint does not make publication-quality maps. I could not get the mapshot or mapshot2 functions in mapview to make a png.
```{r synced_maps}
names(DFobs3a)
names(aug_d_predict1ws_vsci)

vsci_obs <- mapview(DFobs3a, zcol = "vsci", at=seq(0, 90, 15), alpha.regions = .8, legend = TRUE,layer.name = 'Observed Sites VSCI', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "vsci"))) + mapview(vahusb_poly, zcol="subbasin")
vsci_obs

vsci_true <- mapview(aug_d_predict1ws_vsci, zcol = "vsci", at=seq(0, 90, 15), alpha.regions = .8, legend = TRUE,layer.name = 'Prediction Sites True VSCI', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "vsci"))) + mapview(vahusb_poly, zcol="subbasin")

vsci_true

print(sync1 <- sync(vsci_obs, vsci_true, ncol=1))


vsci_pred <- mapview(aug_d_predict1ws_vsci, zcol = "vsci_pred", at=seq(0, 90, 15), alpha.regions = .8, legend = TRUE,layer.name = 'Predictands VSCI', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "vsci_pred"))) + mapview(vahusb_poly, zcol="subbasin")

vsci_pred

print(sync2 <- sync(vsci_true, vsci_pred, ncol =1))

vsci_predse <- mapview(aug_d_predict1ws_vsci, zcol = ".se.fit",  alpha.regions = .8, legend = TRUE,layer.name = 'Predictands VSCI SE', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "st_type", "vsci", "vsci_pred", ".se.fit"))) + mapview(vahusb_poly, zcol="subbasin")

vsci_predse

print(sync3 <- sync(vsci_pred, vsci_predse, ncol=1))

```

# 12 Ribbon Predictand Interval
This is producing a 90% prediction interval because that was the level set when augmented predictions were made.
```{r ribbon_pred_interval}

# ribbon using lower and upper SSN2 prediction intervals

ribbon_pi1 <- ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, shape = st_type, color = st_type, label = station_id_2)) +   geom_point(aes(size = .se.fit)) + 
  geom_abline() + 
  geom_ribbon(aes(ymin = vsci_lwr, ymax = vsci_upr), fill = "grey", alpha = .4) + 
  geom_line(aes( y = vsci_pred)) + 
  labs(x = "Predicted VSCI", y = "TRUE VSCI 2019-2022", title = "SSN Predictions (prediction interval 0.90", subtitle = "Pearson Correlation = 0.57", shape = "Station Type", color = "Station Type") +
  scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

print(ribbon_pi1)
ggplotly(ribbon_pi1)

# opl stands for outside prediction limits
opl_stations2 <- filter(aug_d_predict1ws_vsci, vsci < vsci_lwr | vsci > vsci_upr)

class(opl_stations2)
mapview(opl_stations2, zcol = "station_id_2",  alpha.regions = .8, legend = TRUE,layer.name = 'Outside Prediction Limits', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "st_type", "vsci", "vsci_pred", ".se.fit"))) + mapview(vahusb_poly, zcol="subbasin")

opl_stations2
# given comment "Target and Sampled (no fish or PHAB in 2019?) Dry,no staff", should this site 2-DCK003.94_2019 been sampled?

```

#Exploring residuals and counts at trend vs status

```{r}

## adding in some additional looks at .se.fit vs station type and number of samples.

small_preds = aug_d_predict1ws_vsci%>% select(station_id,st_type,vsci,vsci_pred,.se.fit,.fitted,.residuals)

small_preds_mgm = aug_d_predict1ws_vsci%>% select(station_id2,st_type,vsci,vsci_pred,.se.fit,.fitted,.residuals)


p = ggplot(small_preds, aes(x = .se.fit, y = .residuals,color = st_type))+
  geom_point(aes(label = station_id))
ggplotly(p,hoverinfo = "text")

#small_preds n
small_preds_n = small_preds%>% group_by(station_id,st_type)%>% summarise(n = n())

## loocv
aug_a5obs1ws_vsci$se.fit <- loocv(d_ssn_wswq_reml1,se.fit = T)[[2]]

# small obs
small_obs = aug_a5obs1ws_vsci %>% select(station_id,st_type,vsci,.fitted,.resid,se.fit)

p3 = ggplot(small_obs, aes(x = se.fit, y = .resid,color = st_type))+
  geom_point(aes(label = station_id))
ggplotly(p3,hoverinfo = "text")

# is the .se.fit basically just based on number of samples?
small_obs_n = small_obs%>% select(station_id,st_type)%>%
  group_by(station_id,st_type)%>%
  summarise(n = n())

# so looking at these is appears we maybe have slightly tighter residuals at the trend stations but that would require some more specific distribtuional tests. However the main takeaway is that while the sample size at a point is likely impacting that se.fit value it is not the only driving factor as there are mure se.fit values than there are uniqu sample sizes. 

```

# Figures for Presentations
## SFS 2024 Meeting Torgegram
```{r sfs_torgegram}

# torg2 <- ggplot(flowuncon, aes(x=dist, y=gamma)) + geom_point(size =3) + labs(x = "Flow-Unconnected Stream Distance (m)", y = "Semivariance", title = "VSCI Torgegram Stream Network Distance") + scale_x_continuous(labels=comma)
# png(file="figures_sfs/torg2.png",width=6,height=3,units="in",res=150)
#   torg2
# dev.off()


# esv2 <- ggplot(euclid, aes(x=dist, y=gamma)) + geom_point(size =3) + labs(x = "Euclidean Distance (m)", y = "Semivariance", title = "VSCI Semivariogram Euclidean Distance") + scale_x_continuous(labels=comma)
# png(file="figures_sfs_2024/esv2.png",width=6,height=3,units="in",res=150)
#   esv2
# dev.off()
```

# NMC 2025
## NMC True VSCI vs Pred VSCI Scatter Plot

```{r nmc_pred_true_vsci_stationtype}
# This one is closest
a5preds2019_2022_v3 <- ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, size = .se.fit, shape = st_type, color = st_type)) + geom_point() + labs(x = "Predicted VSCI", y = "True VSCI, 2019-2022", title = "SSN Prediction Sites", shape = "Station Type", color = "Station Type") + xlim(35,80) + ylim(35,80) + scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

png(file="figures_nmc_2025/a5preds2019_2022_v3.png",width=6,height=3,units="in",res=150)
a5preds2019_2022_v3
dev.off()

```

## NMC True VSCI vs Pred VSCI Ribbon Plot
```{r}
ribbon_pi1 <- ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, shape = st_type, color = st_type, label = station_id_2)) + 
  geom_point(aes(size = .se.fit)) + 
  geom_abline() + 
  geom_ribbon(aes(ymin = vsci_lwr, ymax = vsci_upr), fill = "grey", alpha = .4) + 
  geom_line(aes( y = vsci_pred)) + 
  labs(x = "Predicted VSCI", y = "TRUE VSCI 2019-2022", title = "SSN Predictions (prediction interval 0.90)", subtitle = "Pearson Correlation = 0.57", shape = "Station Type", color = "Station Type") +
  scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

print(ribbon_pi1)
ggplotly(ribbon_pi1)

png(file="figures_nmc_2025/ribbon_pi1.png",width=6,height=3,units="in",res=150)
ribbon_pi1
dev.off()

```



## NMC Elevation Boxplots by Subbasin
```{r nmc_boxplots}
RColorBrewer::display.brewer.all()
viridis::viridis(7)
tmaptools::palette_explorer() # zoomed to this and checked options Print color values to get color codes for Brewer Categorical Set3 so I could specify fill colors to match tmaps

boxplot_elev_ws <- ggplot(data=DFobs3a, aes(y= elev_ws, x= vahusb)) + geom_boxplot(aes(fill = vahusb), outlier.shape = NA) + geom_jitter() + labs(y = "Watershed Elevation (m)", x = "Subbasins", fill = "Subbasin") + scale_fill_manual(values = c("#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3"))
  
png(file="figures_nmc_2025/boxplot_elev_ws_v1_20250225.png",width=6,height=3,units="in",res=150)
boxplot_elev_ws
dev.off()


```

## NMC tmap: Prediction Maps

```{r jprobmon}


legend_title = "Subbasin"
tm_shape(vahusb_poly) + tm_polygons("subbasin") +
  tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("right", "TOP"),
  title.position = c('right', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T,  legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

# trying to make subasins legends only so can put in Powerpoint
sb_legend <- tm_shape(vahusb_poly) + tm_polygons("subbasin") +
  tm_layout(legend.only = TRUE)
tmap_save(sb_legend, "figures_nmc_2025/sb_legend.jpeg", width = 2, height = 2, dpi = 150)

# Observed sites
### doing legend.show = F for polygons as I will be placing sb_legend on Powerpoint

j_map_vsci_obs <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(DFobs3a) + 
  tm_bubbles(
  size = "vsci",
  legend.size.show = FALSE,
  col = "vsci",
  legend.col.is.portrait = FALSE,
  style = "fixed",
  palette = "viridis",
  title.col = "VSCI at Observed Sites 2001-2018 (n = 199)",
  breaks = seq(0, 90, by = 15),
  sizes.legend=seq(0, 90, by=15),
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_obs, "figures_nmc_2025/j_map_vsci_obs_v1_20250212.jpeg", width = 7, height = 3.5, dpi = 150)

# map for true vsci predictands

j_map_vsci_true <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(aug_d_predict1ws_vsci) + 
  tm_bubbles(
  size = "vsci",
  legend.size.show = FALSE,
  col = "vsci",
  legend.col.is.portrait = FALSE,
  style = "fixed",
  palette = "viridis",
  title.col = "True VSCI at Prediction Sites 2019-2022 (n = 48)",
  breaks = seq(0, 90, by = 15),
  sizes.legend=seq(0, 90, by=15),
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_true, "figures_nmc_2025/j_map_vsci_true_v1_20250212.jpeg", width = 7, height = 3.5, dpi = 150)


# map for vsci predictands

j_map_vsci_predicted <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(aug_d_predict1ws_vsci) + 
  tm_bubbles(
  size = "vsci_pred",
  legend.size.show = FALSE,
  col = "vsci_pred",
  legend.col.is.portrait = FALSE,
  style = "fixed",
  palette = "viridis",
  title.col = "Predictand VSCI at Prediction Sites 2019-2022 (n = 48)",
  breaks = seq(0, 90, by = 15),
  sizes.legend=seq(0, 90, by=15),
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_predicted, "figures_nmc_2025/j_map_vsci_predictedv1_20250213.jpeg", width = 7, height = 3.5, dpi = 150)

# map for predictand se

j_map_vsci_predse <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(aug_d_predict1ws_vsci) + 
  tm_bubbles(
  size = ".se.fit",
  legend.size.show = FALSE,
  col = ".se.fit",
  legend.col.is.portrait = FALSE,
  style = "cont",
  palette = "viridis",
  title.col = "Standard Error of Predictand VSCI 2019-2022 (n = 48)",
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_predse, "figures_nmc_2025/j_map_vsci_predse_v1_20250225.jpeg", width = 7, height = 3.5, dpi = 150)

```

# TLH Code
Code from Neptune statistician, Travis Linscome-Hatfield, base R plot code to make predictions versus observed. That base R code was replaced with ggplot2 code using geo_ribbon to make prediction intervals for that plot.
# TLH fitted to obs interval plot
On 12/23/2024 commenting this code out b/c this is not the model I need for fitted interval obs plot.

On 12/16/2024 first using a4 reml model and will compare to z5 reml model with distance covariate as that provides a better fit based on smaller AICc value.
```{r fitted_interval_obs_plot}
# z4 model was run above

## fit model
# z4ssn_wswq_ml1 <- ssn_lm(
#   formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
#   ssn.object = j_ssn3,
#   tailup_type = "none",
#   taildown_type = "exponential",
#   euclid_type = "exponential",
#   nugget_type = "nugget",
#   estmethod = "ml",
#   additive = "afv_area",
#   partition_factor = ~ju
# )
# summary(z4ssn_wswq_reml1)

# how do residuals and fitted values below compare to what comes out with augment function?



# class(aug_z4_wswq_reml1)
# names(aug_z4_wswq_reml1)
# 
# head(round(aug_z4_wswq_reml1$.fitted))
# head(round(aug_z4_wswq_reml1$vsci))


# get spatial residuals from model
# spatResids<-residuals(z4ssn_wswq_reml1)
# zspatResids<-residuals(z4ssn_wswq_reml1)
# head(aug_z4ssn_wswq_reml1$.resid)
# the three statements above all return same results

# pull sd of residuals and fitted values
# resid_SD = sd(spatResids)
# fitted_vals = z4ssn_wswq_reml1$fitted$response

# combine to a dataframe
# spat<-cbind(fitted_vals,resid_SD^2)
# head(spat)

# spatial prediction percentiles
# (spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

# spat.Pred.median = spat.Pred.pct[,4]
# head(spat.Pred.median)

# make sure I've got the right obj
# DFobs<-ssn_get_data(j_ssn3)
# observed and median of our prediction intervals
# ty<-DFobs$vsci
# tx<-spat.Pred.median

#percentiles
# ox<-order(tx)
# op05<-spat.Pred.pct[ox,"Q05"]
# op95 <- spat.Pred.pct[ox,"Q95"]

# plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value",ylab="VSCI Observed Value",main="Spatial Model Observed vs. Predicted z4 reml n = 199")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')

# 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
 #legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)

# cor(tx,ty, method = "pearson")

# these object names are used again downstream for preds so remove here

# rm(spatResids,resid_SD,fitted_vals,spat,spat.Pred.pct,spat.Pred.median,ty,tx,ox,op05,op95)
```

# TLH fitted to obs interval plot (LOOCV method)
On 12/26/2024 commenting this code because this is not the model I need for fitted interval obs plot.
```{r fitted_interval_plot_loocv}
# Alrighty, so this method mimics John's method
# which gives a loocv estimate of fitted value an se.
# This results in the squiggly lines because he's giving that 
# se at each individual value.
# cv_resids = loocv(z4ssn_wswq_reml1,
 #                 cv_predict = T,
#                  se.fit = T)
# pull sd of residuals and fitted values
# resid_Se = cv_resids$se.fit
# fitted_vals = cv_resids$cv_predict

# combine to a dataframe
# spat<-cbind(fitted_vals,resid_Se^2)
# head(spat)

# spatial prediction percentiles
# (spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

# spat.Pred.median = spat.Pred.pct[,4]
# head(spat.Pred.median)

# make sure I've got the right obj
# DFobs<-ssn_get_data(j_ssn3)
# observed and median of our prediction intervals
# ty<-DFobs$vsci
# tx<-spat.Pred.median

#percentiles
# ox<-order(tx)
# op05<-spat.Pred.pct[ox,"Q05"]
# op95 <- spat.Pred.pct[ox,"Q95"]

# plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value",ylab="VSCI Observed Value",main="LOOCV Spatial Model Observed vs. Predicted z4 reml")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')

# 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
#legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)

```
# Carson Code Points Outside LOOCV 90% Prediction Limit for n=199 Obs
Added this code on 12/24/2024 and commented out because this is not the final SSN model.
This code comes from local_SSN_FINAL_20160126_modelling.html 
```{r loocv_pts_outside}
# number of points outside 90% prediction limits
# os90pl.sp <-(ty < spat.Pred.pct[,"Q05"]) |  (ty > spat.Pred.pct[,"Q95"]) 
# summary(os90pl.sp)

# which observations are outside [5%, 95%] prediction limits?
# these are the Site IDs of the unusual values
# DFobsz[which(os90pl.sp),"station_id_2"]
```
# TLH fitted to obs interval plot for a5 model
01/14/2025 added Travis' code to make prediction of 199 sites vsci versus observed vsci as ggplot using same variance for each obs so get straight 90th percentile lines. 18 Stations fell outside of those lines.

Now that diagnostics checked out make an observed to fitted interval plot on model a5ssn_wswq_reml1 by augmenting to get diagnostics.
```{r fitted_interval_obs_plot}
# z4 model was run above

a5ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area",
  partition_factor = ~ju
)

tidy(a5ssn_wswq_reml1)
summary(a5ssn_wswq_reml1)
varcomp(a5ssn_wswq_reml1)
loocv(a5ssn_wswq_reml1)

# how do residuals and fitted values below compare to what comes out with augment function?

aug_a5obs1ws_vsci <- augment(a5ssn_wswq_reml1, drop = FALSE)

class(aug_a5obs1ws_vsci)
names(aug_a5obs1ws_vsci)

head(round(aug_a5obs1ws_vsci$.fitted,1))
head(round(aug_a5obs1ws_vsci$vsci,1))


# get spatial residuals from model
spatResids<-residuals(a5ssn_wswq_reml1)
# zspatResids<-residuals(a5ssn_wswq_reml1)
# head(aug_a5obs1ws_vsci$.resid)
# the three statements above all return same results

# pull out fitted values and sd of residuals
fitted_vals = a5ssn_wswq_reml1$fitted$response
resid_SD = sd(spatResids)


# combine to a dataframe note variance same for all obs
spat<-cbind(fitted_vals,resid_SD^2)
head(spat)

# spatial prediction percentiles
(spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

spat.Pred.median = spat.Pred.pct[,4]
head(spat.Pred.median)

# observed and median of our fitted values from 199 obs
ty<-aug_a5obs1ws_vsci$vsci
tx<-round(spat.Pred.median,1)

#percentiles
ox<-order(tx)
op05<-spat.Pred.pct[ox,"Q05"]
op95 <- spat.Pred.pct[ox,"Q95"]

# put all components into data frame for ggplot
plot_dat = data.frame("vsci_pred" = tx, "vsci" = ty, "pred_5th" = op05, "pred_95th" = op95,"vsci_bound_order"=tx[ox],"station_id"=aug_a5obs1ws_vsci$station_id_2)


p = ggplot(data = plot_dat)+
  geom_point(aes(x = vsci_pred, y = vsci,label = station_id), color = "black")+
  geom_smooth(aes(x = vsci_pred, y = vsci), method = "loess", se = F, color = "blue")+
  geom_line(aes(x = vsci_bound_order, y = pred_5th), linetype = "dashed", color = "black")+
  geom_line(aes(x = vsci_bound_order, y = pred_95th), linetype = "dashed", color = "black")+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  labs(x="vsci predicted",
       y ="vsci observed")
print(p)
ggplotly(p)

cor(tx,ty, method = "pearson")

# number of points outside 90% prediction limits
os90pl.sp <-(ty < spat.Pred.pct[,"Q05"]) |  (ty > spat.Pred.pct[,"Q95"]) 
summary(os90pl.sp)

# which observations are outside [5%, 95%] prediction limits?
# these are the Site IDs of the unusual values
aug_a5obs1ws_vsci[which(os90pl.sp),"station_id_2"]

mapview(aug_a5obs1ws_vsci[which(os90pl.sp),"station_id_2"])

# these object names are used again downstream for preds so remove here
rm(spatResids,resid_SD,fitted_vals,spat,spat.Pred.pct,spat.Pred.median,ty,tx,ox,op05,op95,p)

# plot using base plot with all components called separately into the plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value",ylab="VSCI Observed Value",main="SSN Obs vs. Pred a5 reml n = 199")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')

# 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
#legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)

```

# TLH Fitted interval preds
On 01/10/2025 merged Travis' branch to make this as a ggplotly plot
Based on 12/24/2024 email this graph of preds is using standard error of model so that gives straight prediction interval lines
On 12/23/2024, merged Travis' code so that predictions from 48 pred sites also used residuals from the 48 predictions to build the fitted interval.
On 12/19/2025 removed a5ssn_wswq_reml1 and replaced with aug_a5predict1ws_vsci, with that SSN model based on the 48 pred sites.
I believe this coding is fitting to 199 obs because using a5ssn_wswq_reml1. I think it should be using aug_a5predict1ws_vsci as it has 48 predicted sites from 2019-2022.
```{r fitted_interval_preds_plot}
# create residuals in the new prediction frame as they don't provide from the prediction augment call
aug_a5predict1ws_vsci$.residuals <- aug_a5predict1ws_vsci$vsci-aug_a5predict1ws_vsci$.fitted

# use fitted values and calculate sd of residuals
fitted_vals = aug_a5predict1ws_vsci$.fitted
resid_SD = sd(aug_a5predict1ws_vsci$.residuals)

# combine to a dataframe note variance/se is same for all obs
spat<-cbind(fitted_vals,resid_SD^2)
head(spat)
# spatial prediction percentiles
(spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

spat.Pred.median = spat.Pred.pct[,4]

# observed and median of our prediction intervals
ty<-round(aug_a5predict1ws_vsci$vsci,1)
tx<-round(spat.Pred.median,1)

#percentiles
ox<-order(tx)
op05<-spat.Pred.pct[ox,"Q05"]
op95 <- spat.Pred.pct[ox,"Q95"]

# put all components into data frame for ggplot
plot_dat = data.frame("vsci_pred" = tx, "vsci" = ty, "pred_5th" = op05, "pred_95th" = op95,"vsci_bound_order"=tx[ox],"station_id"=aug_a5predict1ws_vsci$station_id_2)


p = ggplot(data = plot_dat)+
  geom_point(aes(x = vsci_pred, y = vsci,label = station_id), color = "black")+
  geom_smooth(aes(x = vsci_pred, y = vsci), method = "loess", se = F, color = "blue")+
  geom_line(aes(x = vsci_bound_order, y = pred_5th), linetype = "dashed", color = "black")+
  geom_line(aes(x = vsci_bound_order, y = pred_95th), linetype = "dashed", color = "black")+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  labs(x="vsci predicted",
       y ="vsci observed",
       title = "SSN Withheld Obs vs Pred a5 reml n=48 interval 0.90, tlh method")
print(p)
ggplotly(p)

# identify does not work in RStudio
# identify(tx, ty, labels = station_id_2, plot=TRUE)

# number of points outside 90% prediction limits
os90pl.sp <-(ty < spat.Pred.pct[,"Q05"]) |  (ty > spat.Pred.pct[,"Q95"]) 
summary(os90pl.sp)

# which observations are outside [5%, 95%] prediction limits?
# these are the Site IDs of the unusual values
aug_a5predict1ws_vsci[which(os90pl.sp),"station_id_2"]

mapview(aug_a5predict1ws_vsci[which(os90pl.sp),"station_id_2"])

rm(fitted_vals, resid_SD, spat, spat.Pred.pct, spat.Pred.median, ty, tx, ox, op05, op95, plot_dat, p, os90pl.sp)

# plot using base plot with all components called separately into the plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value 2019-2022",ylab="VSCI Observed Value 2019-2022",main="SSN Withheld Obs vs. Pred a5 Model SE n =48")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')
# 
# # 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# # 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
# #legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)
```

# TLH Fitted interval preds (quasi-LOOCV method)
On 01/10/2025 merged Travis'branch to make this as a ggplotly plot

On 12/27/2024, is ribbon prediction interval in chunk 20, Preds for Distance Hypothesis, equivalent to chunk 22, fitted_interval_plot_loocv-preds, below? Doing head(aug_a5predict1ws_vsci$vsci_lwr) and same to vsci_upr show ribbon prediction intervals wider than Q05 and Q95. Consequently, the narrower Q05 and Q95 prediction intervals identify more points outside the intervals.

Based on 12/24/2024 email from Travis this uses standard error of each prediction point so get squiggly lines.
```{r fitted_interval_plot_loocv-preds}
# Alrighty, so this method mimics John's method
# which gives a loocv estimate of fitted value an se.
# However, as we're looking at new predicted data it doesn't actually refit the model n times so we don't have proper loocv fitted values.
# This results in the squiggly lines because he's giving that 
# se at each individual value.
fitted_vals = aug_a5predict1ws_vsci$.fitted
resid_Se = aug_a5predict1ws_vsci$.se.fit

# combine to a dataframe and se.fit/variance differs for each observation
spat<-cbind(fitted_vals,resid_Se^2)
head(spat)

# spatial prediction percentiles
# qnorm arguments include
# p a vector of probabilities
# mean a vector of means, which are our fitted values
# sd a vector of standard deviations, the square root of the squared .se.fit
(spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

spat.Pred.median = spat.Pred.pct[,4]
head(spat.Pred.median)


# observed and median of our prediction intervals
ty<-round(aug_a5predict1ws_vsci$vsci,1)
tx<-round(spat.Pred.median,1) ## these just are the fitted values

#percentiles
ox<-order(tx)
op05<-spat.Pred.pct[ox,"Q05"]
op95 <- spat.Pred.pct[ox,"Q95"]

# put all components into data frame for ggplot
plot_dat = data.frame("vsci_pred" = tx, "vsci" = ty, "pred_5th" = op05, "pred_95th" = op95,"vsci_bound_order"=tx[ox],"station_id"=aug_a5predict1ws_vsci$station_id_2)


p = ggplot(data = plot_dat)+
  geom_point(aes(x = vsci_pred, y = vsci,label = station_id), color = "black")+
  geom_smooth(aes(x = vsci_pred, y = vsci), method = "loess", se = F, color = "blue")+
  geom_line(aes(x = vsci_bound_order, y = pred_5th), linetype = "dashed", color = "black")+
  geom_line(aes(x = vsci_bound_order, y = pred_95th), linetype = "dashed", color = "black")+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  labs(x="vsci predicted",
       y ="vsci observed",
       title = "SSN Withheld Obs vs Pred a5 reml n=48 interval 0.90, jhc method")

print(p)
ggplotly(p)

# Carson Code Points Outside LOOCV 90% Prediction Limit for n=48 Withheld Obs
# This code comes from local_SSN_FINAL_20160126_modelling.html that was used in the Scown et al. 2017 paper.

# number of points outside 90% prediction limits
os90pl.sp <-(ty < spat.Pred.pct[,"Q05"]) |  (ty > spat.Pred.pct[,"Q95"]) 
summary(os90pl.sp)

# which observations are outside [5%, 95%] prediction limits?
# these are the Site IDs of the unusual values
aug_a5predict1ws_vsci[which(os90pl.sp),"station_id_2"]

mapview(aug_a5predict1ws_vsci[which(os90pl.sp),"station_id_2"])

rm(fitted_vals, resid_Se, spat, spat.Pred.pct, spat.Pred.median, ty, tx, ox, op05, op95, plot_dat, p, os90pl.sp)

# plot using base plot with all components called in separatel to plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value 2019-2022",ylab="VSCI Observed Value 2019-2022",main="SSN Withheld Obs vs. Pred a5 reml se.fit n =48")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')
# 
# # 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# # 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
# #legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)

# cor(tx,ty, method = "pearson")

```

# ESDA Not Lead Anywhere
Torgegrams DO, TN and Partitioning
In the coefficent plot from Script 05, the flip-flop in instream stressor, being dissolved oxygen at Watershed and Watershed-Riparian, and then total nitrogen for Catchment and Catchment-Riparian suggests that different stressors have their effects on stream condition index at different spatial extents. I thought of following that up in two ways. First, see if semivariograms and Torgegrams of dissolved oxygen and total nitrogen show different ranges, the distance at which observations are independent. My hypothesis is that dissolved oxygen will have a larger range than total nitrogen. Second, I want to see if I update the watershed model to include all 3 instream stressors does that beat the current watershed model having only dissolved oxygen.

On 05/03/2024, not seeing that much spatial structure in DO or Log(TN). On 07/12/2024 still need to test if 3 instream stressors in a model outperforms just DO in the model. Try subsetting ssn objectby ju factor and then making separate Torgegrams.
```{r do_tn_toregrams}
# 
# class(j_ssn3)
# ztg <- SSN2::Torgegram(vscivcpmi ~ 1, j_ssn3, type = c("flowcon", "flowuncon", "euclid"))
# # SSN2::plot.Torgegram(ztg)
# torg <- ztg[["euclid"]]
# names(torg)
# class(torg)
# ggplot(torg, aes(x=dist, y=gamma,size=np)) + geom_point()
# 
# summary(j_ssn3$obs$ju)
# glimpse(j_ssn3$obs$ju)
# 
# #ju yes has 71 obs and no has 128 obs
# # esv_separate <- map(c(yes, no), ~ SSN2::Torgegram(vscivcpmi ~ 1, j_ssn3 |> filter(ju == .x)))
# # 
# # esv_separate
# # 
# # # plot(esv_separate[[1]]) not helpful
# # 
# # esv_ju_yes <- esv_separate[[1]] 
# # esv_ju_no <- esv_separate[[2]]
# # 
# # names(esv_ju_yes)
# # 
# # esv1 <- ggplot(esv_ju_yes, aes(x=dist, y=gamma, size=np)) + geom_point() + labs(x = "Euclidean Distance (m)", y = "Semivariance", title = "JU yes") + scale_x_continuous(labels=comma)
# # 
# # esv2 <- ggplot(esv_ju_no, aes(x=dist, y=gamma, size=np)) + geom_point() + labs(x = "Euclidean Distance (m)", y = "Semivariance", title = "JU no") + scale_x_continuous(labels=comma)
# # 
# 
# 
# 
# ztg <- SSN2::Torgegram(l_tn ~1, j_ssn3, type = c("flowcon", "flowuncon", "euclid"))
# plot(ztg, main = "Torgegram Log(TN)")
# plot(ztg, type = "flowcon", main = "Torgegram Log(TN)")
# plot(ztg, type = "flowuncon", main = "Torgegram Log(TN)")
# plot(ztg, type = "euclid", main = "Torgegram Log(TN)")
# plot(ztg, separate = TRUE, main = "Torgegram Log(TN)")
# 
# flowcon <- ztg[["flowcon"]]
# ggplot(flowcon, aes(x=dist, y=gamma)) + geom_point()
# flowcon$dist_type <- "flow_conn"
# 
# flowuncon <- ztg[["flowuncon"]]
# names(flowuncon)
# class(flowuncon)
# ggplot(flowuncon, aes(x=dist, y=gamma)) + geom_point()
# flowuncon$dist_type <- "flow_unconn"
# 
# euclid <- ztg[["euclid"]]
# names(euclid)
# class(euclid)
# ggplot(euclid, aes(x=dist, y=gamma)) + geom_point()
# euclid$dist_type <- "euclid"
# 
# torg <- bind_rows(flowuncon,euclid)
# ggplot(torg, aes(x=dist, y=gamma, colour = dist_type)) + geom_point()
# 
# # test if Torgegram would work using similar code below
# # esv_separate <- map(c(2001, 2006), ~ esv(log_Zn ~ log_dist2road, moss |> filter(year == .x)))
# 

```

